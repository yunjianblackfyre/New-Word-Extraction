New-Word-Extraction
========
项目简述
========

 招聘信息推荐系统需要分词器提取标签，例如：
 “熟悉机器学习各类算法，并对算法在业务场景的应用”
    
 分词结果：
 * “熟悉” “机器” “学习” “各类” “算法”，
 * “并”“对” “算法” “在” “业务” “场景” “的” “应用”
        
 我们希望能将“机器学习”作为一个独立标签提取出来，而非分别提取出“机器”和“学习”。
    
 新词提取就是要将“机器学习”作为一个独立词语提出，加入分词器训练，使得分词器能产生以下结果：
 * “熟悉” “机器学习” “各类” “算法”，
 * “并”“对” “算法” “在” “业务” “场景” “的” “应用”

方案思路
========
 我们来分析一下两个汉字组合：兄贵 俄罗
 通过我们对爬取数据的分析，我们统计到了如下信息：
 
 * 兄贵是什么      出现50次
 * 兄贵日语怎么说  出现50次
 * 兄贵哲学        出现50次
 * VAN兄贵         出现50次
 * 一位兄贵        出现50次
 * 正太与兄贵      出现50次
 * B站兄贵         出现50次
 * 俄罗斯          出现300次
 
 这样看来，如果我们要猜测“兄贵”左右边最有可能出现什么字，这样会很难，左边可能出现 “VAN” “一位” “正太” “B站”
 右边可能出现 “是什么” “日语” “哲学”，由于出现的次数都是50次，也很难说最有可能出现什么字。
 然而，“俄罗”这个词，我们很确定其右边一定会出现“斯”
 
 在我们的认知中，“兄贵”确实是一个词语，而“俄罗”则不是一个词
 我们可以基本确定，词语的特性之一就是：
 左右两侧出现的字不太容易预测！
 
 有了这样一个特点还不够，因为我们还可以找到一些反例：
 比如，“一晚上”，很明显符合第一条特征，但是并不是一个词啊！
 通过继续分析爬取文本，我们又发现了一些现象，拆分“一晚上”成“一” 和 “晚上”，我们发现：
 
 * “一晚上” 出现100次
 * “一下午” 出现100次
 * “一上午” 出现100次
 * “到了晚上” 出现100次
 * “在晚上” 出现100次
 * “一晚上” 出现100次
 
 拆分“人工智能”成“人工”和“智能”，发现：
 * “人工授精” 出现2次
 * “拥有智能” 出现3次
 * “人工智能” 出现120次
 
 常识告诉我们，“人工智能”是一个独立词语，“一晚上”则不是，这里的区别就是，“人工”总是和“智能”一起出现
 而“一”和“晚上”则不总是一起出现，所以词语的第二个特征：
 则是其组成部分几乎是一起出现的。
 
 在三.中，我们发现了词的两个特征：
 1.左右两侧出现的字不太容易预测
 2.其组成部分几乎是一起出现
 如果我们可以用计算机表达这两个特点，我们就能够写出程序，
 
 * 对于1我们计算词左右字的信息熵即可，以“兄贵”和“俄罗”为例：
    * 熵计算公式为 sum(-p*log(p)) （例如 兄贵是什么      出现50次，概率1/7）
    * Entropy(兄贵)：-(1/7)*log(1/7) - (1/7)*log(1/7) - ...... = -log(1/7) = 1.94
    * Entropy(俄罗)：-log(1/1) = 0
    * 显然，Entropy(兄贵) > Entropy(俄罗) “兄贵”是一个独立词（或者说是独立词的概率很大），“俄罗”则不是
 
 * 对于2我们计算 词分量一起出现与单独出现概率比值，称为Sld（凝固度）
    * Sld(一晚上) = P(一晚上)/(P(一)*P(晚上)) = (1/6)/((4/6)*(4/6)) = 9/24 = 0.375
    * Sld(人工智能) = P(人工智能)/(P(人工)*P(智能)) = (120/125)/((122/125)(123/125)) = 0.99
    * 显然，Sld(人工智能) > Sld(一晚上) “人工智能”是一个独立词，“一晚上”则不是
 
方案步骤
========
 * 1.读取MySQL数据
 * 2.原始内容转码
 * 3.文本预处理
 * 4.计算自由度与凝固度
 * 5.过滤计算结果
 * 6.结果写入文件

方案资源
========
 * 组成：
    * 操作系统：     Linux ubuntu 16.04.2
    * 开发语言：     C++
    * 数据库：       mysql
    * 正则库：       boost::regex
    * JSON库：       jsoncpp
    
 * 安装步骤：
    * C++ boost库
        * boost_1_66_0源码包拷入home文件夹
        * cd boost_1_66_0
        * sudo ./bootstrap.sh --prefix=New-Word-Extraction
        * sudo ./b2 install // 结果写入New-Word-Extraction/lib和同目录include下
    
    * C++ json库
        * 下载jsoncpp源码 http://sourceforge.net/projects/jsoncpp/files/
        * 解压jsoncpp到/opt/json下 tar -zvxf jsoncpp-src-0.5.0.tar.gz -C /opt/json
        * 下载完后阅读README，发现需要用Scons来构建，关于Scons的介绍参考:http://os.51cto.com/art/201104/257443.htm，那么就下载Scons吧
        * 下载Scons http://sourceforge.net/projects/scons/files/scons/2.1.0/scons-2.1.0.tar.gz/download
        * 解压Scons到/opt/json下 tar -zvxf scons-2.1.0.tar.gz -C /opt/json
        * 进入scons-2.1.0目录下，执行以下命令 sudo python setup.py install
        * 进入jsoncpp文件夹的libs，将下面的.a与.so文件拷贝至New-Word-Extraction/lib下
        * 进入jsoncpp文件夹的include，将下面的json文件夹拷贝至New-Word-Extraction/include下
        
    * C++ MySQL库
        * 在线安装：sudo apt-get install libmysqlclient-dev
        * 找到/usr/lib/x86_64-linux-gnu/libmysqlclient.so文件，并拷贝至New-Word-Extraction/lib下
        
    * 编译
        * 进入New-Word-Extraction
        * 执行cmake .
        * 执行make
        * 可执行文件在New-Word-Extraction/build/bin/下

结果示意
========
 由于篇幅有限，这里只展示20个新词：
 * 机器学习 机器视觉 深度学习 海量数据 电机控制 
 * 硬件驱动 移动终端 阿里云 风控 飞控 
 * 静态页面 视频编码 网页前端 美术制作 运维
 * 起薪 微博 微信 手游 手机应用


